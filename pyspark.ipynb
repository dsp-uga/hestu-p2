{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_NUM_TREES=300\n",
    "RF_MAX_DEPTH=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import findspark\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds and adds spark to python path\n",
    "# Convenient for env managers like conda\n",
    "\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier, LinearSVC, LogisticRegression\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, FloatType, ArrayType, StringType, DoubleType\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an initial spark configuration utilizing all local cores\n",
    "conf = SparkConf().setMaster(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates spark context through which to process RDD ops\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName(\"Word Count\")\\\n",
    "                    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mold(df, labeled=True):\n",
    "    df = df.select([df.columns[1]]+df.columns[145:])\n",
    "\n",
    "    df = df.withColumn(df.schema.names[0],col(df.schema.names[0]).cast(\"Long\")).withColumnRenamed(\"Face ID\", \"face_id\")\n",
    "\n",
    "    offset= 2 if labeled else 1\n",
    "    for i in range(len(df.schema.names)-offset):\n",
    "        df = df.withColumn(df.schema.names[1+i],col(df.schema.names[1+i]).cast(\"Float\"))\n",
    "    if labeled:\n",
    "        df = df.withColumn('Y',col(df.schema.names[-1]).cast(\"Integer\")).drop('Sex (subj)')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train=spark.read.load(\"X_small_train.csv\", format=\"csv\", header=True)\n",
    "_test=spark.read.load(\"X_small_test.csv\", format=\"csv\", header=True)\n",
    "big_train=spark.read.load(\"X_train.csv\", format=\"csv\", header=True)\n",
    "_testA=spark.read.load(\"Xa_test.csv\", format=\"csv\", header=True)\n",
    "_testB=spark.read.load(\"Xb_test.csv\", format=\"csv\", header=True)\n",
    "_testC=spark.read.load(\"Xc_test.csv\", format=\"csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingData=mold(_train)\n",
    "trainingDataBig=mold(big_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingData=mold(_test)\n",
    "testingDataA=mold(_testA,False)\n",
    "testingDataB=mold(_testB,False)\n",
    "testingDataC=mold(_testC,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(train,model_type='rf'):\n",
    "    \n",
    "    if model_type=='lr':\n",
    "        train=train.withColumn(\"bias\", lit(1)).select([train.schema.names[0],'bias']+train.schema.names[1:])\n",
    "\n",
    "    train_assembler = VectorAssembler().setInputCols(train.schema.names[1:-1]).setOutputCol('features')\n",
    "\n",
    "    trainData=train_assembler.transform(train).selectExpr('face_id','features',\"Y\")\n",
    "\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"Y\", outputCol=\"indexedLabel\").fit(trainData)\n",
    "\n",
    "\n",
    "    # Create model templates.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=RF_NUM_TREES,maxDepth=RF_MAX_DEPTH)\n",
    "    \n",
    "    gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\",maxDepth=RF_MAX_DEPTH, maxIter=100)\n",
    "\n",
    "    layers = [len(train.schema.names[1:-1]), 256, 256, 2]\n",
    "    perceptron = MultilayerPerceptronClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\",maxIter=400, layers=layers, blockSize=128)\n",
    "\n",
    "    lsvc = LinearSVC(labelCol=\"indexedLabel\", featuresCol=\"features\",maxIter=40, regParam=0.1)\n",
    "\n",
    "    lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\",maxIter=400, regParam=0.0, elasticNetParam=0)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    _model={'rf':rf,'gbt':gbt,'per':perceptron,'svm':lsvc,'lr':lr}[model_type]\n",
    "    pipeline = Pipeline(stages=[labelIndexer, _model, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainData)\n",
    "\n",
    "    return model\n",
    "    # Make predictions.\n",
    "    #if model_type=='lr':\n",
    "    #    predictions = model.predict(testData)\n",
    "    #else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(test,model,model_type='rf',labeled=True):\n",
    "    if model_type=='lr':\n",
    "        test=test.withColumn(\"bias\", lit(1)).select([test.schema.names[0],'bias']+test.schema.names[1:])\n",
    "\n",
    "    _names=test.schema.names[1:-1] if labeled else test.schema.names[1:]\n",
    "    test_assembler = VectorAssembler().setInputCols(_names).setOutputCol('features')\n",
    "\n",
    "    cols=['face_id','features']\n",
    "    if labeled:\n",
    "        cols+=['Y']\n",
    "    testData=test_assembler.transform(test).select(*cols)\n",
    "\n",
    "    \n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    out_cols=['face_id','predictedLabel']\n",
    "    # Select example rows to display.\n",
    "    if labeled:\n",
    "        out_cols+=['Y']\n",
    "    return predictions.select(*out_cols).rdd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=buildModel(trainingDataBig,model_type='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=testModel(testingDataC,model,model_type='lr',labeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(face_id=280177, predictedLabel='1', Y=1),\n",
       " Row(face_id=9559, predictedLabel='1', Y=0),\n",
       " Row(face_id=393795, predictedLabel='0', Y=0),\n",
       " Row(face_id=157822, predictedLabel='0', Y=0),\n",
       " Row(face_id=962033, predictedLabel='1', Y=1),\n",
       " Row(face_id=142054, predictedLabel='0', Y=0),\n",
       " Row(face_id=6563, predictedLabel='1', Y=0),\n",
       " Row(face_id=840223, predictedLabel='1', Y=0),\n",
       " Row(face_id=963342, predictedLabel='0', Y=1),\n",
       " Row(face_id=757875, predictedLabel='0', Y=0),\n",
       " Row(face_id=315910, predictedLabel='0', Y=0),\n",
       " Row(face_id=678490, predictedLabel='1', Y=1),\n",
       " Row(face_id=319563, predictedLabel='0', Y=0),\n",
       " Row(face_id=549436, predictedLabel='0', Y=0),\n",
       " Row(face_id=731076, predictedLabel='0', Y=1),\n",
       " Row(face_id=163999, predictedLabel='1', Y=1),\n",
       " Row(face_id=641028, predictedLabel='0', Y=1),\n",
       " Row(face_id=375392, predictedLabel='1', Y=1),\n",
       " Row(face_id=926786, predictedLabel='1', Y=1),\n",
       " Row(face_id=545577, predictedLabel='0', Y=0),\n",
       " Row(face_id=281026, predictedLabel='0', Y=0),\n",
       " Row(face_id=197294, predictedLabel='1', Y=1),\n",
       " Row(face_id=722268, predictedLabel='1', Y=1),\n",
       " Row(face_id=408488, predictedLabel='1', Y=1),\n",
       " Row(face_id=851523, predictedLabel='0', Y=0),\n",
       " Row(face_id=583386, predictedLabel='0', Y=0),\n",
       " Row(face_id=668294, predictedLabel='1', Y=1),\n",
       " Row(face_id=84703, predictedLabel='1', Y=1),\n",
       " Row(face_id=488510, predictedLabel='0', Y=0),\n",
       " Row(face_id=388099, predictedLabel='1', Y=1),\n",
       " Row(face_id=550651, predictedLabel='0', Y=0),\n",
       " Row(face_id=344977, predictedLabel='0', Y=0),\n",
       " Row(face_id=254599, predictedLabel='0', Y=0),\n",
       " Row(face_id=267852, predictedLabel='0', Y=1),\n",
       " Row(face_id=365361, predictedLabel='0', Y=1),\n",
       " Row(face_id=533244, predictedLabel='0', Y=1),\n",
       " Row(face_id=313794, predictedLabel='1', Y=1),\n",
       " Row(face_id=958332, predictedLabel='1', Y=1),\n",
       " Row(face_id=253255, predictedLabel='1', Y=1),\n",
       " Row(face_id=799459, predictedLabel='0', Y=0),\n",
       " Row(face_id=351521, predictedLabel='1', Y=1),\n",
       " Row(face_id=113670, predictedLabel='0', Y=0),\n",
       " Row(face_id=46752, predictedLabel='0', Y=0),\n",
       " Row(face_id=421976, predictedLabel='0', Y=0),\n",
       " Row(face_id=95742, predictedLabel='0', Y=0),\n",
       " Row(face_id=552897, predictedLabel='1', Y=1),\n",
       " Row(face_id=300895, predictedLabel='1', Y=1),\n",
       " Row(face_id=821806, predictedLabel='1', Y=1),\n",
       " Row(face_id=220925, predictedLabel='1', Y=0),\n",
       " Row(face_id=475019, predictedLabel='1', Y=1),\n",
       " Row(face_id=1193, predictedLabel='0', Y=0),\n",
       " Row(face_id=812887, predictedLabel='0', Y=1),\n",
       " Row(face_id=684227, predictedLabel='1', Y=1),\n",
       " Row(face_id=69320, predictedLabel='1', Y=0),\n",
       " Row(face_id=874768, predictedLabel='1', Y=0),\n",
       " Row(face_id=774429, predictedLabel='1', Y=1),\n",
       " Row(face_id=350683, predictedLabel='1', Y=1),\n",
       " Row(face_id=237783, predictedLabel='1', Y=1),\n",
       " Row(face_id=402109, predictedLabel='0', Y=0),\n",
       " Row(face_id=4267, predictedLabel='1', Y=1),\n",
       " Row(face_id=810471, predictedLabel='1', Y=1),\n",
       " Row(face_id=159045, predictedLabel='0', Y=0),\n",
       " Row(face_id=93133, predictedLabel='0', Y=0),\n",
       " Row(face_id=570034, predictedLabel='1', Y=1),\n",
       " Row(face_id=597218, predictedLabel='0', Y=0),\n",
       " Row(face_id=56323, predictedLabel='0', Y=0),\n",
       " Row(face_id=239219, predictedLabel='1', Y=0),\n",
       " Row(face_id=934552, predictedLabel='1', Y=1),\n",
       " Row(face_id=381376, predictedLabel='0', Y=0),\n",
       " Row(face_id=88722, predictedLabel='1', Y=0),\n",
       " Row(face_id=11448, predictedLabel='0', Y=1),\n",
       " Row(face_id=545874, predictedLabel='1', Y=1),\n",
       " Row(face_id=918238, predictedLabel='0', Y=0),\n",
       " Row(face_id=404939, predictedLabel='0', Y=1),\n",
       " Row(face_id=449129, predictedLabel='0', Y=0),\n",
       " Row(face_id=891008, predictedLabel='0', Y=0),\n",
       " Row(face_id=124950, predictedLabel='0', Y=1),\n",
       " Row(face_id=59983, predictedLabel='0', Y=0),\n",
       " Row(face_id=250991, predictedLabel='1', Y=1),\n",
       " Row(face_id=191297, predictedLabel='0', Y=1),\n",
       " Row(face_id=629986, predictedLabel='1', Y=1),\n",
       " Row(face_id=396567, predictedLabel='1', Y=1),\n",
       " Row(face_id=568351, predictedLabel='1', Y=1),\n",
       " Row(face_id=550987, predictedLabel='0', Y=0),\n",
       " Row(face_id=424922, predictedLabel='0', Y=0),\n",
       " Row(face_id=875631, predictedLabel='0', Y=0),\n",
       " Row(face_id=580136, predictedLabel='0', Y=1),\n",
       " Row(face_id=879875, predictedLabel='1', Y=0),\n",
       " Row(face_id=407973, predictedLabel='0', Y=0),\n",
       " Row(face_id=662195, predictedLabel='0', Y=1),\n",
       " Row(face_id=675005, predictedLabel='0', Y=1),\n",
       " Row(face_id=755700, predictedLabel='0', Y=0),\n",
       " Row(face_id=301075, predictedLabel='0', Y=0),\n",
       " Row(face_id=180897, predictedLabel='0', Y=0),\n",
       " Row(face_id=329492, predictedLabel='0', Y=0),\n",
       " Row(face_id=748582, predictedLabel='0', Y=0),\n",
       " Row(face_id=182224, predictedLabel='0', Y=0),\n",
       " Row(face_id=174696, predictedLabel='0', Y=1),\n",
       " Row(face_id=266728, predictedLabel='0', Y=0),\n",
       " Row(face_id=684535, predictedLabel='1', Y=1),\n",
       " Row(face_id=342875, predictedLabel='1', Y=1),\n",
       " Row(face_id=277183, predictedLabel='1', Y=1),\n",
       " Row(face_id=881131, predictedLabel='1', Y=1),\n",
       " Row(face_id=517337, predictedLabel='1', Y=1),\n",
       " Row(face_id=43127, predictedLabel='1', Y=0),\n",
       " Row(face_id=762078, predictedLabel='1', Y=0),\n",
       " Row(face_id=608330, predictedLabel='0', Y=0),\n",
       " Row(face_id=367737, predictedLabel='0', Y=0),\n",
       " Row(face_id=422032, predictedLabel='0', Y=0),\n",
       " Row(face_id=601870, predictedLabel='0', Y=0),\n",
       " Row(face_id=936593, predictedLabel='1', Y=1),\n",
       " Row(face_id=619447, predictedLabel='1', Y=0),\n",
       " Row(face_id=385979, predictedLabel='0', Y=0)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.collect()[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(out):\n",
    "    count=0\n",
    "    for o in out:\n",
    "        if int(o[1])==o[2]:\n",
    "            count+=1\n",
    "    return count/len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7604562737642585"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(output.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest='yc.txt'\n",
    "with open(dest, 'a') as the_file:\n",
    "    for row in output.collect():\n",
    "        the_file.write(f'{row[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
