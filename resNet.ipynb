{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "below is for local load only \n",
    "\"\"\"\n",
    "# im_names = os.listdir('/home/clint/project2/images')\n",
    "# path = '/home/clint/project2/files/'\n",
    "# name = 'Xa_test.csv'\n",
    "# names = os.listdir(path)\n",
    "# df1 = pd.DataFrame()\n",
    "# for name in names:\n",
    "#     print(name)\n",
    "#     df2 = pd.read_csv(f'{path}{name}')\n",
    "#     df1 = df1.append(df2, ignore_index=True)\n",
    " \n",
    "# df_select = df1[df1['Image File'].isin(im_names)]\n",
    "# df_select2 = df_select.dropna()\n",
    "\n",
    "# df_val = df_select2.sample(int(len(df_select2)*.2/200))\n",
    "# df_train = df_select2[~df_select2.index.isin(df_val.index.tolist())]\n",
    "# df_train = df_train.sample(int(len(df_train)/200))\n",
    "\n",
    "# data_val = P2DataLoader(df_val, root='/home/clint/project2/images')\n",
    "# data_train = P2DataLoader(df_train, root='/home/clint/project2/images')\n",
    "# dataload_val = DataLoader(data_val, batch_size=4, shuffle=True, num_workers=0)\n",
    "# dataload_train = DataLoader(data_train, batch_size=4, shuffle=True, num_workers=0)\n",
    "# dataloaders = {'train':dataload_train, 'val': dataload_val}\n",
    "# dataset_sizes = {'train':len(df_train),'val':len(df_val)}\n",
    "\n",
    "\n",
    "class P2DataLoader():\n",
    "    def __init__(self, df, root='', train=True, transform=None,):\n",
    "        \n",
    "        # path to image data\n",
    "#         self.csv_data = pd.read_csv(csv_file)\n",
    "        self.root = root\n",
    "        self.csv_data = df\n",
    "        self.target = np.array(self.csv_data['Sex (subj)']) # label of image\n",
    "        self.im_file = np.array(self.csv_data['Image File']) # label of image\n",
    "        self.h = np.array(self.csv_data['Image Height'])\n",
    "        self.w = np.array(self.csv_data['Image Width'])\n",
    "        self.x1 = np.array(self.csv_data['X (top left)'])\n",
    "        self.x2 = np.array(self.csv_data['X (bottom right)'])\n",
    "        self.y1 = np.array(self.csv_data['Y (top left)'])\n",
    "        self.y2 = np.array(self.csv_data['Y (bottom right)'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            dict: {'image': image, 'target': index of target class, 'meta': dict}\n",
    "        \"\"\"\n",
    "        #make slicer from bbox\n",
    "        img, target, h, w = io.imread(f'{self.root}/{self.im_file[index]}'), self.target[index], self.h[index], self.w[index]\n",
    "        # slicer from bbox\n",
    "        img = img[self.y1[index]:self.y2[index],self.x1[index]:self.x2[index]]\n",
    "        # resize to a standard size\n",
    "        img = cv2.resize(img , (64, 64))\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.reshape(3, 64, 64)\n",
    "        \n",
    "        \"\"\"\n",
    "        I have a transform library we can use here\n",
    "        \"\"\"\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "        out = {'image': img,\n",
    "               'target': int(target),\n",
    "               'meta': {'im_size': (h, w), 'index': index, 'class_ID': target}}\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_image(self, index):\n",
    "        img = index\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "    \n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    start = time.time()\n",
    "    gold_acc, gold_model_wts = 0.0, copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            current_corrects, current_loss = 0, 0.0\n",
    "            # Here's where the training happens\n",
    "            print('Iterating through data...')\n",
    "\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs = data['image'].to(device)\n",
    "                labels = data['target'].to(device)\n",
    "\n",
    "                # We need to zero the gradients, don't forget it\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                \"\"\"\n",
    "                forward\n",
    "                \"\"\"\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    \"\"\"\n",
    "                    backward\n",
    "                    \"\"\"\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # loss statistics\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            e_loss = current_loss / dataset_sizes[phase]\n",
    "            epoch_ac = current_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, e_loss, epoch_ac))\n",
    "\n",
    "            \"\"\"\n",
    "            copy only if the model improved\n",
    "            \"\"\"\n",
    "            if phase == 'val' and epoch_ac > gold_acc:\n",
    "                gold_acc = epoch_ac\n",
    "                gold_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "    end = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        end // 60, end % 60))\n",
    "    print('Best val Acc: {:4f}'.format(gold_acc))\n",
    "\n",
    "    # Now we'll load in the best model weights and return it\n",
    "    model.load_state_dict(gold_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def Tain_ResNet(path2trainCSV, val_fract, path2ims, num_epochs=25):\n",
    "    \"\"\"\n",
    "    load data\n",
    "    inputs: path2trainCSV, val_fract, path2ims\n",
    "    \"\"\"\n",
    "    df =  pd.read_csv(path2trainCSV)\n",
    "    df_val = df.sample(int(len(sample)*val_fract))\n",
    "    df_train = df[~df.index.isin(df_val.index)]\n",
    "\n",
    "    data_val = P2DataLoader(df_val, root=path2ims)\n",
    "    data_train = P2DataLoader(df_train, root=path2ims)\n",
    "    dataload_val = DataLoader(data_val, batch_size=4, shuffle=True, num_workers=0)\n",
    "    dataload_train = DataLoader(data_train, batch_size=4, shuffle=True, num_workers=0)\n",
    "    dataloaders = {'train':dataload_train, 'val': dataload_val}\n",
    "    dataset_sizes = {'train':len(df_train),'val':len(df_val)}\n",
    "\n",
    "    \"\"\"\n",
    "    build res\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    res_mod = models.resnet34(pretrained=True)\n",
    "    num_ftrs = res_mod.fc.in_features\n",
    "    res_mod.fc = nn.Linear(num_ftrs, 2)\n",
    "    res_mod = res_mod.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_ft = optim.SGD(res_mod.parameters(), lr=0.001, momentum=0.9) # Observe that all parameters are being optimized\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)# Decay LR by a factor of 0.1 every 7 epochs\n",
    "\n",
    "    \"\"\"\n",
    "    train\n",
    "    \"\"\"\n",
    "    base_model = train_model(res_mod, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
